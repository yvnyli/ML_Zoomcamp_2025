{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07277e32-5cda-4fa3-897d-f36aca4aba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1811e293-9953-4f51-b208-281f90168a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"cleaned_df_features.pkl\", \"rb\") as f:\n",
    "    df, numerics, curated_cat, other_cat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab54ee72-a7a0-4a64-a704-3c8d0957bba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14514552, 13)\n",
      "(3628639, 13)\n",
      "(2015911, 13)\n"
     ]
    }
   ],
   "source": [
    "# first we split trials\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# 10% for testing\n",
    "[df_full_train,df_test] = train_test_split(df,test_size=0.1,random_state=42)\n",
    "# 72% and 18% for train/val\n",
    "[df_train,df_val] = train_test_split(df_full_train,test_size=0.2,random_state=42)\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de2b9c6-7c94-4474-a122-41f3710c33a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data too large\n",
    "del df\n",
    "del df_full_train\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca8af29-8568-4897-903b-d51084a66537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get response variable out\n",
    "\n",
    "y_test = df_test.base_passenger_fare.values\n",
    "y_val = df_val.base_passenger_fare.values\n",
    "y_train = df_train.base_passenger_fare.values\n",
    "\n",
    "df_test = df_test.drop(columns=['base_passenger_fare'])\n",
    "df_val = df_val.drop(columns=['base_passenger_fare'])\n",
    "df_train = df_train.drop(columns=['base_passenger_fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b3cbc-3e8f-4a75-ab3a-978aa39af31a",
   "metadata": {},
   "source": [
    "### starting with the curated feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47c9fbf8-71cb-4c12-a34e-75523625cb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DV took  3.14 min\n",
      "(14514552, 40)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['day_of_week=Friday', 'day_of_week=Monday', 'day_of_week=Saturday',\n",
       "       'day_of_week=Sunday', 'day_of_week=Thursday',\n",
       "       'day_of_week=Tuesday', 'day_of_week=Wednesday', 'hour_of_day=0',\n",
       "       'hour_of_day=1', 'hour_of_day=10', 'hour_of_day=11',\n",
       "       'hour_of_day=12', 'hour_of_day=13', 'hour_of_day=14',\n",
       "       'hour_of_day=15', 'hour_of_day=16', 'hour_of_day=17',\n",
       "       'hour_of_day=18', 'hour_of_day=19', 'hour_of_day=2',\n",
       "       'hour_of_day=20', 'hour_of_day=21', 'hour_of_day=22',\n",
       "       'hour_of_day=23', 'hour_of_day=3', 'hour_of_day=4',\n",
       "       'hour_of_day=5', 'hour_of_day=6', 'hour_of_day=7', 'hour_of_day=8',\n",
       "       'hour_of_day=9', 'hvfhs_license_num=Juno',\n",
       "       'hvfhs_license_num=Lyft', 'hvfhs_license_num=Uber',\n",
       "       'hvfhs_license_num=Via', 'shared_flag_or', 'trip_miles_log1p',\n",
       "       'trip_time_log1p', 'wait_time_sec_log1p', 'wav_request_flag'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding: fit from training set\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import time\n",
    "\n",
    "dv_cur = DictVectorizer(sparse=True)\n",
    "\n",
    "# this takes some time\n",
    "t0 = time.time()\n",
    "\n",
    "# curated features only\n",
    "X_cur_train = dv_cur.fit_transform(df_train[numerics + curated_cat].to_dict(orient='records'))\n",
    "X_cur_val = dv_cur.transform(df_val[numerics + curated_cat].to_dict(orient='records'))\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print(f\"DV took {(t1-t0)/60:5.2f} min\")\n",
    "print(X_cur_train.shape)\n",
    "\n",
    "with open(\"dv_cur.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dv_cur, f)\n",
    "\n",
    "with open(\"X_cur_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_cur_train, f)\n",
    "\n",
    "with open(\"X_cur_val.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_cur_val, f)\n",
    "    \n",
    "dv_cur.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2ea874f-a94d-4191-8c92-aa8776103216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['wait_time_sec_log1p', 'trip_time_log1p', 'trip_miles_log1p'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftns_cur = dv_cur.get_feature_names_out()\n",
    "ftns_cur[[40-2,40-3,40-4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7833635-d6be-40bd-a6ba-8bea54f17947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:     16.88 GB\n",
      "Available: 6.54 GB\n",
      "Used:      10.34 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "mem = psutil.virtual_memory()\n",
    "print(f\"Total:     {mem.total/1e9:.2f} GB\")\n",
    "print(f\"Available: {mem.available/1e9:.2f} GB\")\n",
    "print(f\"Used:      {mem.used/1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f86953-79f5-4fe4-bbc6-b14aa56a13b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.576e-06\n",
      "8.06498256\n",
      "1.451455204\n"
     ]
    }
   ],
   "source": [
    "import pympler.asizeof as aso\n",
    "print(aso.asizeof(dv_cur) / 1e9)\n",
    "print(aso.asizeof(df_train) / 1e9)\n",
    "size_bytes = (\n",
    "    X_cur_train.data.nbytes +\n",
    "    X_cur_train.indices.nbytes +\n",
    "    X_cur_train.indptr.nbytes\n",
    ")\n",
    "print(size_bytes / 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2110ef10-8e9f-4ef5-afa8-f539618886fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "||||||| curated features |||||||\n",
      "\n",
      "\n",
      "=== Ridge (L2) hyperparameter search ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee1479e6a2c413783499d299fca9972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ridge alphas:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=  0.0000 | train_RMSE=  9.9316 | val_RMSE=  9.9607 | time= 0.32 min\n",
      "alpha=  0.1000 | train_RMSE=  9.9316 | val_RMSE=  9.9607 | time= 0.31 min\n",
      "alpha=  1.0000 | train_RMSE=  9.9316 | val_RMSE=  9.9607 | time= 0.30 min\n",
      "alpha= 10.0000 | train_RMSE=  9.9316 | val_RMSE=  9.9607 | time= 0.31 min\n",
      "alpha=100.0000 | train_RMSE=  9.9316 | val_RMSE=  9.9607 | time= 0.31 min\n",
      "\n",
      "Best Ridge alpha: 0.1\n",
      "Best Ridge training RMSE: 9.9316\n",
      "Best Ridge validation RMSE: 9.9607\n",
      "Best Ridge training time: 0.31 minutes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Optional: progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"\\n||||||| curated features |||||||\\n\")\n",
    "\n",
    "# ------------------------------------\n",
    "# 1. Linear models: L2 (Ridge) search\n",
    "# ------------------------------------\n",
    "\n",
    "# Note: with one-hot/sparse features, use with_mean=False\n",
    "# If X_* are sparse, this will keep them sparse where possible.\n",
    "\n",
    "\n",
    "# only scale 3 numeric features\n",
    "numeric_idx = [36,37,38]\n",
    "all_idx = list(range(40))\n",
    "cat_idx = [j for j in all_idx if j not in numeric_idx]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=False), numeric_idx),\n",
    "        (\"cat\", \"passthrough\", cat_idx),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "ridge_alphas = [0.0, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "print(\"\\n=== Ridge (L2) hyperparameter search ===\")\n",
    "\n",
    "ridge_results = []\n",
    "for alpha in tqdm(ridge_alphas, desc=\"Ridge alphas\"):\n",
    "    model_ridge = Pipeline([\n",
    "        (\"scaler\", preprocess),  # safe for sparse\n",
    "        (\"reg\", Ridge(alpha=alpha, random_state=0))\n",
    "    ])\n",
    "\n",
    "    t0 = time.time()\n",
    "    model_ridge.fit(X_cur_train, y_train)\n",
    "\n",
    "    y_pred = model_ridge.predict(X_cur_train)\n",
    "    rmse_train = root_mean_squared_error(y_train, y_pred)\n",
    "    \n",
    "    y_pred = model_ridge.predict(X_cur_val)\n",
    "    rmse_val = root_mean_squared_error(y_val, y_pred)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    train_time = t1 - t0\n",
    "\n",
    "    print(f\"alpha={alpha:8.4f} | train_RMSE={rmse_train:8.4f} | val_RMSE={rmse_val:8.4f} | time={train_time/60:5.2f} min\")\n",
    "    ridge_results.append((alpha, rmse_train, rmse_val, train_time, model_ridge))\n",
    "\n",
    "# Pick best Ridge by validation RMSE\n",
    "best_ridge_alpha, best_ridge_rmse_train, best_ridge_rmse_val, best_ridge_time, best_ridge_model = min(\n",
    "    ridge_results,\n",
    "    key=lambda x: x[2]\n",
    ")\n",
    "\n",
    "print(f\"\\nBest Ridge alpha: {best_ridge_alpha}\")\n",
    "print(f\"Best Ridge training RMSE: {best_ridge_rmse_train:.4f}\")\n",
    "print(f\"Best Ridge validation RMSE: {best_ridge_rmse_val:.4f}\")\n",
    "print(f\"Best Ridge training time: {best_ridge_time/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54bd8a27-7052-4854-9b4f-5a389112e8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline train RMSE: 16.1098770146206\n",
      "Baseline valid RMSE: 16.13452728439628\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_baseline = np.full_like(y_train, np.mean(y_train), dtype=float)\n",
    "y_val_pred_baseline = np.full_like(y_val, np.mean(y_train), dtype=float)\n",
    "\n",
    "print(\"Baseline train RMSE:\", root_mean_squared_error(y_train, y_train_pred_baseline))\n",
    "print(\"Baseline valid RMSE:\", root_mean_squared_error(y_val, y_val_pred_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa51ca6-45cb-4478-a527-6c634238b539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73e4798c-329c-4350-b909-7fed404e9206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ElasticNet hyperparameter search ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92fbfdfa43e4d3e95a1716dce200f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SGD ElasticNet alphas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356d43603caa415fa14b237bf30a9bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "l1 ratio:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.000010 | l1r=  0.0000 | train_RMSE= 10.2701 | val_RMSE= 10.2980 | time= 3.63 min\n",
      "alpha=0.000010 | l1r=  0.0500 | train_RMSE= 10.2704 | val_RMSE= 10.2983 | time= 3.68 min\n",
      "alpha=0.000010 | l1r=  0.1000 | train_RMSE= 10.2706 | val_RMSE= 10.2985 | time= 3.50 min\n",
      "alpha=0.000010 | l1r=  0.2000 | train_RMSE= 10.2701 | val_RMSE= 10.2980 | time= 3.66 min\n",
      "alpha=0.000010 | l1r=  0.5000 | train_RMSE= 10.2703 | val_RMSE= 10.2982 | time= 3.62 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54493cb0561946cf9f92593a2362eea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "l1 ratio:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.000100 | l1r=  0.0000 | train_RMSE= 10.2702 | val_RMSE= 10.2981 | time= 3.94 min\n",
      "alpha=0.000100 | l1r=  0.0500 | train_RMSE= 10.2705 | val_RMSE= 10.2984 | time= 4.17 min\n",
      "alpha=0.000100 | l1r=  0.1000 | train_RMSE= 10.2705 | val_RMSE= 10.2984 | time= 3.60 min\n",
      "alpha=0.000100 | l1r=  0.2000 | train_RMSE= 10.2707 | val_RMSE= 10.2986 | time= 3.61 min\n",
      "alpha=0.000100 | l1r=  0.5000 | train_RMSE= 10.2702 | val_RMSE= 10.2981 | time= 3.71 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663a361fab824586b3f72c88b7f51eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "l1 ratio:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.001000 | l1r=  0.0000 | train_RMSE= 10.2715 | val_RMSE= 10.2994 | time= 4.32 min\n",
      "alpha=0.001000 | l1r=  0.0500 | train_RMSE= 10.2720 | val_RMSE= 10.2999 | time= 3.87 min\n",
      "alpha=0.001000 | l1r=  0.1000 | train_RMSE= 10.2715 | val_RMSE= 10.2993 | time= 3.63 min\n",
      "alpha=0.001000 | l1r=  0.2000 | train_RMSE= 10.2814 | val_RMSE= 10.3092 | time= 3.59 min\n",
      "alpha=0.001000 | l1r=  0.5000 | train_RMSE= 10.2717 | val_RMSE= 10.2996 | time= 3.62 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046be93769e148f5a4ba02b90f1c67ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "l1 ratio:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.010000 | l1r=  0.0000 | train_RMSE= 10.3064 | val_RMSE= 10.3343 | time= 3.42 min\n",
      "alpha=0.010000 | l1r=  0.0500 | train_RMSE= 10.2952 | val_RMSE= 10.3231 | time= 3.50 min\n",
      "alpha=0.010000 | l1r=  0.1000 | train_RMSE= 10.3049 | val_RMSE= 10.3328 | time= 3.40 min\n",
      "alpha=0.010000 | l1r=  0.2000 | train_RMSE= 10.2840 | val_RMSE= 10.3118 | time= 4.13 min\n",
      "alpha=0.010000 | l1r=  0.5000 | train_RMSE= 10.2911 | val_RMSE= 10.3190 | time= 4.18 min\n",
      "\n",
      "Best SGD alpha: 1e-05\n",
      "Best SGD L1 ratio: 0.2000\n",
      "Best SGD training RMSE: 10.2701\n",
      "Best SGD validation RMSE: 10.2980\n",
      "Best SGD training time: 3.66 minutes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "\n",
    "# only scale 3 numeric features\n",
    "numeric_idx = [36,37,38]\n",
    "all_idx = list(range(40))\n",
    "cat_idx = [j for j in all_idx if j not in numeric_idx]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=False), numeric_idx),\n",
    "        (\"cat\", \"passthrough\", cat_idx),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "SGDalphas = [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "l1_ratios = [0.0, 0.05, 0.1, 0.2, 0.5]\n",
    "\n",
    "print(\"\\n=== ElasticNet hyperparameter search ===\")\n",
    "SGD_results = []\n",
    "\n",
    "for alpha in tqdm(SGDalphas, desc=\"SGD ElasticNet alphas\"):\n",
    "    for l1r in tqdm(l1_ratios, desc=\"l1 ratio\", leave=False):\n",
    "    \n",
    "        model_SGD = Pipeline([\n",
    "            (\"scaler\", preprocess),\n",
    "            (\"reg\", SGDRegressor( \\\n",
    "                loss=\"squared_error\",\n",
    "                penalty=\"elasticnet\",\n",
    "                alpha=alpha,\n",
    "                l1_ratio=l1r,\n",
    "                eta0=1e-6,\n",
    "                max_iter=100,\n",
    "                shuffle=True,\n",
    "                early_stopping=True,\n",
    "                n_iter_no_change=5,\n",
    "                validation_fraction=0.1,\n",
    "                tol=1e-3,\n",
    "                verbose=0)\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        t0 = time.time()\n",
    "        model_SGD.fit(X_cur_train, y_train)\n",
    "    \n",
    "        y_pred = model_SGD.predict(X_cur_train)\n",
    "        rmse_train = root_mean_squared_error(y_train, y_pred)\n",
    "        \n",
    "        y_pred = model_SGD.predict(X_cur_val)\n",
    "        rmse_val = root_mean_squared_error(y_val, y_pred)\n",
    "        \n",
    "        t1 = time.time()\n",
    "        train_time = t1 - t0\n",
    "        \n",
    "        print(f\"alpha={alpha:8.6f} | l1r={l1r:8.4f} | train_RMSE={rmse_train:8.4f} | val_RMSE={rmse_val:8.4f} | time={train_time/60:5.2f} min\")\n",
    "        SGD_results.append((alpha, l1r, rmse_train, rmse_val, train_time, model_SGD))\n",
    "\n",
    "\n",
    "with open(\"curated_SGDEN_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump((SGD_results, l1_ratios, SGDalphas), f)\n",
    "\n",
    "best_SGD_alpha, best_SGD_l1r, best_SGD_rmse_train, best_SGD_rmse_val, best_SGD_time, best_SGD_model = min(\n",
    "    SGD_results,\n",
    "    key=lambda x: x[3]\n",
    ")\n",
    "\n",
    "print(f\"\\nBest SGD alpha: {best_SGD_alpha}\")\n",
    "print(f\"Best SGD L1 ratio: {best_SGD_l1r:.4f}\")\n",
    "print(f\"Best SGD training RMSE: {best_SGD_rmse_train:.4f}\")\n",
    "print(f\"Best SGD validation RMSE: {best_SGD_rmse_val:.4f}\")\n",
    "print(f\"Best SGD training time: {best_SGD_time/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb5c5a-b05c-4d8d-ace8-18a9dd05572d",
   "metadata": {},
   "source": [
    "### summary for Ridge and SGD Elastic Net regression with curated features\n",
    "\n",
    "Ridge trains very fast (<1min) and SGD is a lot slower (a few minutes per model and more hyperparams). \n",
    "\n",
    "Both had similar performances, with ridge being slightly better (RMSE= \\$9.96 vs \\$10.30). \n",
    "\n",
    "(This is not what I expected. I think it might be because I did not pick the best hyperparams for SGD and did not let it train for very long.) \n",
    "\n",
    "Both training and validation RMSE are large, although they are better than the baseline model of mean (RMSE=\\$16). \n",
    "\n",
    "Given the median fare is $10, the model is completely underfitting. \n",
    "\n",
    "Maybe the curated features are not informative enough, or the linear regression model is too biased, or maybe RMSE is not a good metric for training because of the skewness of our target variable.\n",
    "\n",
    "In any case, I will try XGBoost next. Hopefully a more flexible model will give us better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85fe73c8-a719-4cf9-ae45-5a4687ea4a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:     16.88 GB\n",
      "Available: 2.60 GB\n",
      "Used:      14.27 GB\n"
     ]
    }
   ],
   "source": [
    "mem = psutil.virtual_memory()\n",
    "print(f\"Total:     {mem.total/1e9:.2f} GB\")\n",
    "print(f\"Available: {mem.available/1e9:.2f} GB\")\n",
    "print(f\"Used:      {mem.used/1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21ceeddc-e971-4308-9c29-766fd9b9dcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval (early stopping) on 1451456 rows\n",
      "train (CV tuning) on 2612620 rows\n",
      "\n",
      "=== XGBoost hyperparameter search ===\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "XGB Best params: {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 8, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "XGB Best CV score (RMSE): 6.492647753591704\n",
      "XGB search time: 379.53 minutes\n",
      "XGB training RMSE (best model): 6.4728\n",
      "XGB validation RMSE (best model): 6.5263\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#from xgboost import XGBRegressor\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "#from scipy.stats import randint\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 3. XGBoost: randomized search\n",
    "# -------------------------------\n",
    "\n",
    "# portion out some data from _train for early stopping\n",
    "X_temp, X_stop_xgb, y_temp, y_stop_xgb = train_test_split(\n",
    "    X_cur_train, y_train, test_size=0.1, random_state=42)\n",
    "# use fewer data for training for speed\n",
    "X_temp, X_train_xgb, y_temp, y_train_xgb = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"eval (early stopping) on {y_stop_xgb.shape[0]:d} rows\")\n",
    "print(f\"train (CV tuning) on {y_train_xgb.shape[0]:d} rows\")\n",
    "\n",
    "# Define parameter distribution\n",
    "param_dist = {\n",
    "    'max_depth': [3,4,5,6,7,8],\n",
    "    'learning_rate': [0.3, 0.2, 0.1, 0.05, 0.01],\n",
    "    'min_child_weight': [1, 5, 10, 20],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create XGBClassifier\n",
    "xgb = XGBRegressor(\n",
    "    tree_method=\"hist\",\n",
    "    enable_categorical=True,  # if using pandas categorical dtypes\n",
    "    n_estimators=2000,        # large, rely on early stopping\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\",\n",
    "    early_stopping_rounds=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "fit_params = {\n",
    "    \"eval_set\": [(X_stop_xgb, y_stop_xgb)],\n",
    "    \"verbose\": False,\n",
    "}\n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,          # e.g. 50 random trials\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=2,          # shows progress of the search\n",
    "    n_jobs=1,\n",
    "    cv=3   \n",
    ")\n",
    "\n",
    "print(\"\\n=== XGBoost hyperparameter search ===\")\n",
    "t0 = time.time()\n",
    "search.fit(X_train_xgb, y_train_xgb, **fit_params)\n",
    "t1 = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"XGB Best params:\", search.best_params_)\n",
    "print(\"XGB Best CV score (RMSE):\", -search.best_score_)\n",
    "print(f\"XGB search time: {(t1 - t0)/60:.2f} minutes\")\n",
    "\n",
    "best_xgb = search.best_estimator_\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"curated_xgboost_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump((search, best_xgb, X_stop_xgb, y_stop_xgb, X_train_xgb, y_train_xgb), f)\n",
    "    \n",
    "# Evaluate best XGB on validation set explicitly:\n",
    "y_pred_xgb = best_xgb.predict(X_cur_train)\n",
    "xgb_train_rmse = root_mean_squared_error(y_train, y_pred_xgb)\n",
    "\n",
    "y_pred_xgb = best_xgb.predict(X_cur_val)\n",
    "xgb_val_rmse = root_mean_squared_error(y_val, y_pred_xgb)\n",
    "print(f\"XGB training RMSE (best model): {xgb_train_rmse:.4f}\")\n",
    "print(f\"XGB validation RMSE (best model): {xgb_val_rmse:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# 4. Summary of model comparison\n",
    "# ------------------------------------\n",
    "\n",
    "#print(\"\\n=== Summary (validation RMSE) ===\")\n",
    "#print(f\"Ridge (L2)   : {best_ridge_rmse:.4f}  (alpha={best_ridge_alpha})\")\n",
    "#print(f\"XGBoost      : {xgb_val_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97e97880-bc20-470e-8b1b-fd930cf7c7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>mean_CV_RMSE</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>94.018815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.492648</td>\n",
       "      <td>0.073968</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>101.153698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.493559</td>\n",
       "      <td>0.072633</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>67.857698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.495601</td>\n",
       "      <td>0.074099</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>600.627969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.495954</td>\n",
       "      <td>0.068021</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>372.150743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.496433</td>\n",
       "      <td>0.072570</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>79.833502</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.499159</td>\n",
       "      <td>0.068402</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>41.788510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.500068</td>\n",
       "      <td>0.071850</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>196.109713</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.500827</td>\n",
       "      <td>0.074907</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>77.216035</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.502138</td>\n",
       "      <td>0.072641</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.063687</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.504243</td>\n",
       "      <td>0.072561</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>237.652168</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.504266</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.561397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.505483</td>\n",
       "      <td>0.073475</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>49.107864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.505595</td>\n",
       "      <td>0.076886</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>45.552443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.506489</td>\n",
       "      <td>0.071152</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23.167565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.508040</td>\n",
       "      <td>0.067752</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69.868580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.508797</td>\n",
       "      <td>0.072150</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>64.234127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.508976</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>21.045663</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.509553</td>\n",
       "      <td>0.070941</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>45.495358</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.510272</td>\n",
       "      <td>0.072221</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>252.635764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.510728</td>\n",
       "      <td>0.066557</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.707952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.510926</td>\n",
       "      <td>0.068247</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>35.700951</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.511792</td>\n",
       "      <td>0.067521</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>80.218593</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.512106</td>\n",
       "      <td>0.064830</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>366.403917</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.513533</td>\n",
       "      <td>0.072428</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>50.850200</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.517306</td>\n",
       "      <td>0.072370</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>442.681015</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.518252</td>\n",
       "      <td>0.067362</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>26.524007</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.518403</td>\n",
       "      <td>0.079156</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15.257772</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.519760</td>\n",
       "      <td>0.066705</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127.778103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.520771</td>\n",
       "      <td>0.075261</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>77.910667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.520779</td>\n",
       "      <td>0.069646</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>15.203707</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.523680</td>\n",
       "      <td>0.075487</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>95.316561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.524920</td>\n",
       "      <td>0.070059</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>11.173198</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.527789</td>\n",
       "      <td>0.061847</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.994457</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.532391</td>\n",
       "      <td>0.065293</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22.023932</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.532746</td>\n",
       "      <td>0.071523</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.468568</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.533029</td>\n",
       "      <td>0.066784</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>581.470870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.533118</td>\n",
       "      <td>0.074289</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47.471679</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.534265</td>\n",
       "      <td>0.071327</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>529.611634</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.538647</td>\n",
       "      <td>0.069887</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>12.840590</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.541873</td>\n",
       "      <td>0.066799</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>46.515487</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.545087</td>\n",
       "      <td>0.073272</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>100.863066</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.548084</td>\n",
       "      <td>0.072195</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.063132</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.558856</td>\n",
       "      <td>0.065394</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.066720</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.559763</td>\n",
       "      <td>0.071644</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>50.661708</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.563104</td>\n",
       "      <td>0.067498</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>207.102263</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.572449</td>\n",
       "      <td>0.080210</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>47.954283</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.583729</td>\n",
       "      <td>0.074979</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>606.065249</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.591813</td>\n",
       "      <td>0.069429</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>610.804873</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.592314</td>\n",
       "      <td>0.071708</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>585.231749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.594788</td>\n",
       "      <td>0.072364</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  param_subsample  param_min_child_weight  param_max_depth  \\\n",
       "37      94.018815              1.0                      10                8   \n",
       "21     101.153698              1.0                      10                7   \n",
       "44      67.857698              1.0                       5                5   \n",
       "49     600.627969              1.0                      20                6   \n",
       "9      372.150743              1.0                       1                7   \n",
       "12      79.833502              0.8                      20                7   \n",
       "36      41.788510              1.0                      10                6   \n",
       "47     196.109713              1.0                      10                5   \n",
       "39      77.216035              0.6                       1                7   \n",
       "3       40.063687              1.0                       5                8   \n",
       "32     237.652168              0.6                      10                7   \n",
       "0       24.561397              1.0                       1                8   \n",
       "28      49.107864              1.0                       1                8   \n",
       "30      45.552443              1.0                      20                6   \n",
       "7       23.167565              1.0                      10                7   \n",
       "6       69.868580              1.0                      10                5   \n",
       "24      64.234127              1.0                      10                4   \n",
       "45      21.045663              0.8                      10                8   \n",
       "22      45.495358              0.6                       5                6   \n",
       "33     252.635764              1.0                       1                4   \n",
       "25      13.707952              1.0                      20                8   \n",
       "40      35.700951              0.6                       5                7   \n",
       "48      80.218593              0.6                      20                6   \n",
       "2      366.403917              0.8                       5                5   \n",
       "41      50.850200              0.8                       1                5   \n",
       "29     442.681015              0.6                      20                5   \n",
       "46      26.524007              0.8                       1                8   \n",
       "26      15.257772              0.8                      20                7   \n",
       "1      127.778103              1.0                      20                4   \n",
       "34      77.910667              0.8                       1                5   \n",
       "35      15.203707              0.6                       5                8   \n",
       "18      95.316561              1.0                       5                3   \n",
       "42      11.173198              0.8                       1                8   \n",
       "10      12.994457              0.6                      10                8   \n",
       "23      22.023932              0.8                       5                5   \n",
       "5       23.468568              0.6                      10                5   \n",
       "20     581.470870              1.0                       5                4   \n",
       "8       47.471679              0.8                      10                4   \n",
       "27     529.611634              0.8                      10                4   \n",
       "38      12.840590              0.6                       5                8   \n",
       "11      46.515487              0.6                       5                4   \n",
       "43     100.863066              0.6                       1                4   \n",
       "4       75.063132              0.8                      20                3   \n",
       "16      18.066720              0.6                       1                5   \n",
       "31      50.661708              0.8                      10                3   \n",
       "17     207.102263              0.8                       1                3   \n",
       "15      47.954283              0.6                      10                3   \n",
       "14     606.065249              0.8                      20                3   \n",
       "13     610.804873              0.8                       5                3   \n",
       "19     585.231749              1.0                       5                3   \n",
       "\n",
       "    param_learning_rate  param_colsample_bytree  mean_CV_RMSE  std_test_score  \\\n",
       "37                 0.05                     0.6      6.492648        0.073968   \n",
       "21                 0.05                     0.6      6.493559        0.072633   \n",
       "44                 0.20                     0.6      6.495601        0.074099   \n",
       "49                 0.01                     0.6      6.495954        0.068021   \n",
       "9                  0.01                     0.6      6.496433        0.072570   \n",
       "12                 0.05                     0.8      6.499159        0.068402   \n",
       "36                 0.20                     0.6      6.500068        0.071850   \n",
       "47                 0.05                     0.6      6.500827        0.074907   \n",
       "39                 0.05                     0.6      6.502138        0.072641   \n",
       "3                  0.10                     0.8      6.504243        0.072561   \n",
       "32                 0.01                     1.0      6.504266        0.070377   \n",
       "0                  0.20                     0.6      6.505483        0.073475   \n",
       "28                 0.05                     1.0      6.505595        0.076886   \n",
       "30                 0.10                     1.0      6.506489        0.071152   \n",
       "7                  0.20                     1.0      6.508040        0.067752   \n",
       "6                  0.10                     1.0      6.508797        0.072150   \n",
       "24                 0.30                     0.6      6.508976        0.078688   \n",
       "45                 0.20                     0.8      6.509553        0.070941   \n",
       "22                 0.10                     0.6      6.510272        0.072221   \n",
       "33                 0.05                     0.6      6.510728        0.066557   \n",
       "25                 0.30                     1.0      6.510926        0.068247   \n",
       "40                 0.10                     0.8      6.511792        0.067521   \n",
       "48                 0.05                     1.0      6.512106        0.064830   \n",
       "2                  0.01                     0.8      6.513533        0.072428   \n",
       "41                 0.10                     0.6      6.517306        0.072370   \n",
       "29                 0.01                     0.6      6.518252        0.067362   \n",
       "46                 0.10                     1.0      6.518403        0.079156   \n",
       "26                 0.30                     0.8      6.519760        0.066705   \n",
       "1                  0.10                     1.0      6.520771        0.075261   \n",
       "34                 0.05                     1.0      6.520779        0.069646   \n",
       "35                 0.20                     0.8      6.523680        0.075487   \n",
       "18                 0.30                     0.6      6.524920        0.070059   \n",
       "42                 0.30                     1.0      6.527789        0.061847   \n",
       "10                 0.30                     0.8      6.532391        0.065293   \n",
       "23                 0.30                     0.8      6.532746        0.071523   \n",
       "5                  0.20                     0.8      6.533029        0.066784   \n",
       "20                 0.01                     0.8      6.533118        0.074289   \n",
       "8                  0.20                     0.8      6.534265        0.071327   \n",
       "27                 0.01                     0.8      6.538647        0.069887   \n",
       "38                 0.30                     0.8      6.541873        0.066799   \n",
       "11                 0.10                     0.8      6.545087        0.073272   \n",
       "43                 0.05                     1.0      6.548084        0.072195   \n",
       "4                  0.20                     1.0      6.558856        0.065394   \n",
       "16                 0.30                     1.0      6.559763        0.071644   \n",
       "31                 0.30                     1.0      6.563104        0.067498   \n",
       "17                 0.05                     0.6      6.572449        0.080210   \n",
       "15                 0.30                     0.6      6.583729        0.074979   \n",
       "14                 0.01                     1.0      6.591813        0.069429   \n",
       "13                 0.01                     0.8      6.592314        0.071708   \n",
       "19                 0.01                     0.8      6.594788        0.072364   \n",
       "\n",
       "    rank  \n",
       "37     1  \n",
       "21     2  \n",
       "44     3  \n",
       "49     4  \n",
       "9      5  \n",
       "12     6  \n",
       "36     7  \n",
       "47     8  \n",
       "39     9  \n",
       "3     10  \n",
       "32    11  \n",
       "0     12  \n",
       "28    13  \n",
       "30    14  \n",
       "7     15  \n",
       "6     16  \n",
       "24    17  \n",
       "45    18  \n",
       "22    19  \n",
       "33    20  \n",
       "25    21  \n",
       "40    22  \n",
       "48    23  \n",
       "2     24  \n",
       "41    25  \n",
       "29    26  \n",
       "46    27  \n",
       "26    28  \n",
       "1     29  \n",
       "34    30  \n",
       "35    31  \n",
       "18    32  \n",
       "42    33  \n",
       "10    34  \n",
       "23    35  \n",
       "5     36  \n",
       "20    37  \n",
       "8     38  \n",
       "27    39  \n",
       "38    40  \n",
       "11    41  \n",
       "43    42  \n",
       "4     43  \n",
       "16    44  \n",
       "31    45  \n",
       "17    46  \n",
       "15    47  \n",
       "14    48  \n",
       "13    49  \n",
       "19    50  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the results\n",
    "results = search.cv_results_\n",
    "df_results = pd.DataFrame({\n",
    "    \"mean_fit_time\": results[\"mean_fit_time\"],\n",
    "    \"param_subsample\": results[\"param_subsample\"],\n",
    "    \"param_min_child_weight\": results[\"param_min_child_weight\"],\n",
    "    \"param_max_depth\": results[\"param_max_depth\"],\n",
    "    \"param_learning_rate\": results[\"param_learning_rate\"],\n",
    "    \"param_colsample_bytree\": results[\"param_colsample_bytree\"],\n",
    "    \"mean_CV_RMSE\": -results[\"mean_test_score\"],\n",
    "    \"std_test_score\": results[\"std_test_score\"],\n",
    "    \"rank\": results[\"rank_test_score\"],\n",
    "})\n",
    "\n",
    "df_results.sort_values(\"rank\",inplace=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fdbcca1-3881-4573-b28a-81c0e2be5153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50.000000\n",
       "mean      6.525098\n",
       "std       0.027249\n",
       "min       6.492648\n",
       "25%       6.505818\n",
       "50%       6.517779\n",
       "75%       6.533978\n",
       "max       6.594788\n",
       "Name: mean_CV_RMSE, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[\"mean_CV_RMSE\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2114074e-fe8d-4555-bddd-81835411cc84",
   "metadata": {},
   "source": [
    "### summary for XGBoost with curated features\n",
    "XGBoost's RMSE is stuck very closely around $6.5 for both train and val. Hyperparameters make little difference to performance. This suggest underfitting. Because XGBoost is very powerful and flexible, I think the limiting factor is the curated features. It's time to use all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c6ec0-cead-4504-875b-c20d1dcc4413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
